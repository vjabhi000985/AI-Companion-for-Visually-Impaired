# Percevia: AI Companion for the Visually Impaired üëÅÔ∏è‚Äçüó®Ô∏è‚ú®

**Percevia** is an AI-powered web application designed to assist visually impaired individuals by leveraging cutting-edge technologies like Generative AI, Image Processing, and Speech Recognition. This app provides real-time scene understanding, text-to-speech conversion, object detection, and personalized assistance to improve accessibility and independence for users.

This project was developed as the final task of the Data Science and Gen AI Internship at Innomatics Research Labs, and it incorporates state-of-the-art AI models for real-time assistance.

## Features üöÄ

- **Real-Time Scene Understanding**:

  - Uses Generative AI to describe the environment for visually impaired users. This feature analyzes the scene and provides a vivid, empathetic description that enhances understanding and safety.

- **Text-to-Speech Conversion**:

  - Extracts text from images using Optical Character Recognition (OCR) and converts it into speech, enabling users to read printed text or documents via audio.

- **Object Detection**:

  - Detects objects and obstacles in images to provide safety warnings or context-based assistance, improving situational awareness.

- **Personalized Assistance**:
  - Provides contextual guidance to users by analyzing images and offering actionable information to assist with everyday tasks.

## Technologies Used üõ†Ô∏è

- **Python**: Core programming language for AI, image processing, and web app development.
- **Streamlit**: Web framework used to build and deploy the application.
- **Google‚Äôs Generative AI (ChatGoogleGenerativeAI)**: For real-time scene interpretation and contextual assistance.
- **PIL (Python Imaging Library)**: For handling image manipulation and processing.
- **Tesseract OCR**: For extracting text from images.
- **pyttsx3**: For converting extracted text to speech.
- **Lottie**: For displaying animations and creating dynamic spinner/loading effects in the web app.
